{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DAL.data import *\n",
    "from DAL.data_eval import *\n",
    "from Train.finetuning import *\n",
    "from Collect.results import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "from utils import *\n",
    "load_env_variables()\n",
    "from time import sleep\n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "Scheduling experiment with paraphrase count = 1 and 25...\n",
      "WARNING:root:Training and validation files are created and saved in <data/train-1-25.jsonl> and <data/valid-25.jsonl>.\n",
      "WARNING:root:File names have been added to the experiments list.\n",
      "WARNING:root:Data files have been evaluated.\n",
      "d:\\Parspack Project\\CodeChallenge\\DAL\\data_eval.py:180: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '{'length': 100, 'format_errors': defaultdict(<class 'int'>, {}), 'n_missing_system': 0, 'n_missing_user': 0, 'num_messages_per_example': {'min': 3, 'max': 3, 'mean': 3.0, 'median': 3.0, 'p5': 3.0, 'p95': 3.0}, 'num_total_tokens_per_example': {'min': 149, 'max': 483, 'mean': 244.16, 'median': 205.0, 'p5': 172.0, 'p95': 357.6}, 'num_assistant_tokens_per_example': {'min': 28, 'max': 334, 'mean': 102.4, 'median': 55.0, 'p5': 38.0, 'p95': 199.0}, 'n_billing_tokens_in_dataset': 24416, 'n_epochs': 3}' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[index_of_value, ['Stats']] = str(stats)\n",
      "WARNING:root:Statistics related to each file have been added to the tracker file.\n",
      "WARNING:root:Files have been successfully uploaded to OpenAI servers.\n",
      "d:\\Parspack Project\\CodeChallenge\\Train\\finetuning.py:47: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'file-mvnsDRFXsXKU70DKrJEijuqp' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[index_of_value, ['OpenAI FileID']] = file_id\n",
      "WARNING:root:Related FileIDs have been added to the tracker file.\n",
      "WARNING:root:Finetune job has been scheduled successfully.\n",
      "WARNING:root:The job is added to the file.\n",
      "WARNING:root:\n",
      "Scheduling experiment with paraphrase count = 2 and 50...\n",
      "WARNING:root:Training and validation files are created and saved in <data/train-2-50.jsonl> and <data/valid-50.jsonl>.\n",
      "WARNING:root:File names have been added to the experiments list.\n",
      "WARNING:root:Data files have been evaluated.\n",
      "WARNING:root:Statistics related to each file have been added to the tracker file.\n",
      "WARNING:root:Files have been successfully uploaded to OpenAI servers.\n",
      "WARNING:root:Related FileIDs have been added to the tracker file.\n",
      "WARNING:root:Finetune job has been scheduled successfully.\n",
      "WARNING:root:The job is added to the file.\n",
      "WARNING:root:\n",
      "Scheduling experiment with paraphrase count = 3 and 75...\n",
      "WARNING:root:Training and validation files are created and saved in <data/train-3-75.jsonl> and <data/valid-75.jsonl>.\n",
      "WARNING:root:File names have been added to the experiments list.\n",
      "WARNING:root:Data files have been evaluated.\n",
      "WARNING:root:Statistics related to each file have been added to the tracker file.\n",
      "WARNING:root:Files have been successfully uploaded to OpenAI servers.\n",
      "WARNING:root:Related FileIDs have been added to the tracker file.\n",
      "WARNING:root:Finetune job has been scheduled successfully.\n",
      "WARNING:root:The job is added to the file.\n",
      "WARNING:root:\n",
      "Scheduling experiment with paraphrase count = 3 and 100...\n",
      "WARNING:root:Training and validation files are created and saved in <data/train-3-100.jsonl> and <data/valid-100.jsonl>.\n",
      "WARNING:root:File names have been added to the experiments list.\n",
      "WARNING:root:Data files have been evaluated.\n",
      "WARNING:root:Statistics related to each file have been added to the tracker file.\n",
      "WARNING:root:Files have been successfully uploaded to OpenAI servers.\n",
      "WARNING:root:Related FileIDs have been added to the tracker file.\n",
      "WARNING:root:Finetune job has been scheduled successfully.\n",
      "WARNING:root:The job is added to the file.\n"
     ]
    }
   ],
   "source": [
    "experiments = [(1, 25), (2, 50), (3, 75), (3, 100)]\n",
    "job_ids = []\n",
    "for exp in experiments:\n",
    "    logging.warning(f'\\nScheduling experiment with paraphrase count = {exp[0]} and {exp[1]}...')\n",
    "    train, valid = create_subset(*exp)\n",
    "    logging.warning(f'Training and validation files are created and saved in <{train}> and <{valid}>.')\n",
    "    track_samples(train)\n",
    "    track_samples(valid)\n",
    "    logging.warning(f'File names have been added to the experiments list.')\n",
    "    train_stats = eval_dataset(train)\n",
    "    valid_stats = eval_dataset(valid)\n",
    "    logging.warning(f'Data files have been evaluated.')\n",
    "    track_stats(train, train_stats)\n",
    "    track_stats(valid, valid_stats)\n",
    "    logging.warning(f'Statistics related to each file have been added to the tracker file.')\n",
    "    training_id = upload_file(train)\n",
    "    validation_id = upload_file(valid)\n",
    "    logging.warning(f'Files have been successfully uploaded to OpenAI servers.')\n",
    "    track_fileid(train, training_id)\n",
    "    track_fileid(valid, validation_id)\n",
    "    logging.warning(f'Related FileIDs have been added to the tracker file.')\n",
    "    job_id = create_model(training_id, validation_id)\n",
    "    logging.warning(f'Finetune job has been scheduled successfully.')\n",
    "    track_job(job_id)\n",
    "    logging.warning(f'The job is added to the file.')\n",
    "    job_ids.append(job_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:['ftjob-5jXekfGrsNIPst6JA5TbP9rH', 'ftjob-lCzdvOo4xxm6qGyYparMylxb', 'ftjob-Zfam5lkswdg1uNH8gaD1lINb', 'ftjob-fS6yk4juP75gQJI4WZMySj1P']\n"
     ]
    }
   ],
   "source": [
    "job_ids = ['ftjob-5jXekfGrsNIPst6JA5TbP9rH', 'ftjob-lCzdvOo4xxm6qGyYparMylxb', 'ftjob-Zfam5lkswdg1uNH8gaD1lINb', 'ftjob-fS6yk4juP75gQJI4WZMySj1P']\n",
    "logging.warning(job_ids)\n",
    "copy_of_job_ids = copy(job_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Checking status for job ID=ftjob-5jXekfGrsNIPst6JA5TbP9rH to determine if it is completed...\n",
      "WARNING:root:failed\n",
      "WARNING:root:Error(code='exceeded_quota', message='Creating this fine-tuning job would exceed your hard limit, please check your plan and billing details', param=None)\n",
      "WARNING:root:Checking status for job ID=ftjob-lCzdvOo4xxm6qGyYparMylxb to determine if it is completed...\n",
      "WARNING:root:failed\n",
      "WARNING:root:Error(code='exceeded_quota', message='Creating this fine-tuning job would exceed your hard limit, please check your plan and billing details', param=None)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m         copy_of_job_ids\u001b[38;5;241m.\u001b[39mremove(job_id)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 13\u001b[0m         sleep(\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     14\u001b[0m sleep(\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy_of_job_ids\u001b[38;5;241m==\u001b[39m[]:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    for job_id in copy_of_job_ids:\n",
    "        logging.warning(f'Checking status for job ID={job_id} to determine if it is completed...')\n",
    "        is_done = check_job(job_id)\n",
    "        if is_done:\n",
    "            logging.warning(f'Job ID={job_id} has completed. Model specifications are added to the list.')\n",
    "            track_model(job_id)\n",
    "            logging.warning(f'Result file for job ID={job_id} is stored in <./runs>.')\n",
    "            track_job(job_id)\n",
    "            track_result(job_id)\n",
    "            copy_of_job_ids.remove(job_id)\n",
    "        else:\n",
    "            sleep(10)\n",
    "    sleep(10)\n",
    "    if copy_of_job_ids==[]:\n",
    "        break \n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
